{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HitzJack/BCS_Workshop_2023/blob/main/Task.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hand Gesture Detection assignment**\n",
        "\n",
        "\n",
        "2.   Instruction/Hints are mentioned, to run the cell you have to do shift+enter\n",
        "\n"
      ],
      "metadata": {
        "id": "eGP-BSmIV919"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opendatasets\n",
        "!pip install keras\n",
        "!pip install tensorflow\n",
        "!pip install rasa==1.1.4"
      ],
      "metadata": {
        "id": "B6i6nDzwSbyj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9cc8dfa-8b0f-4959-e9d5-5fccb91a2ea5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opendatasets in /usr/local/lib/python3.10/dist-packages (0.1.22)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from opendatasets) (4.66.1)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (from opendatasets) (1.5.16)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from opendatasets) (8.1.7)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.31.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.0.6)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (6.0.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle->opendatasets) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle->opendatasets) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle->opendatasets) (3.4)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.13.1)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.13.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.1.21 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.59.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: keras<2.14,>=2.13.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.13.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: numpy<=1.24.3,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.14,>=2.13 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.13.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.13.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.34.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.41.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (3.4.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (3.2.2)\n",
            "Collecting rasa==1.1.4\n",
            "  Using cached rasa-1.1.4-py3-none-any.whl (447 kB)\n",
            "Requirement already satisfied: requests~=2.22 in /usr/local/lib/python3.10/dist-packages (from rasa==1.1.4) (2.31.0)\n",
            "Collecting boto3~=1.9 (from rasa==1.1.4)\n",
            "  Using cached boto3-1.28.62-py3-none-any.whl (135 kB)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from rasa==1.1.4) (3.7.1)\n",
            "Collecting simplejson~=3.16 (from rasa==1.1.4)\n",
            "  Using cached simplejson-3.19.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (137 kB)\n",
            "Requirement already satisfied: attrs>=18 in /usr/local/lib/python3.10/dist-packages (from rasa==1.1.4) (23.1.0)\n",
            "Collecting jsonpickle~=1.1 (from rasa==1.1.4)\n",
            "  Using cached jsonpickle-1.5.2-py2.py3-none-any.whl (37 kB)\n",
            "Collecting redis~=3.2 (from rasa==1.1.4)\n",
            "  Using cached redis-3.5.3-py2.py3-none-any.whl (72 kB)\n",
            "Collecting fakeredis~=1.0 (from rasa==1.1.4)\n",
            "  Using cached fakeredis-1.10.2-py3-none-any.whl (43 kB)\n",
            "Collecting pymongo~=3.8 (from rasa==1.1.4)\n",
            "  Using cached pymongo-3.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (516 kB)\n",
            "Requirement already satisfied: numpy~=1.16 in /usr/local/lib/python3.10/dist-packages (from rasa==1.1.4) (1.23.5)\n",
            "Requirement already satisfied: scipy~=1.2 in /usr/local/lib/python3.10/dist-packages (from rasa==1.1.4) (1.11.3)\n",
            "INFO: pip is looking at multiple versions of rasa to determine which version is compatible with other requirements. This could take a while.\n",
            "\u001b[31mERROR: Ignored the following versions that require a different python version: 1.10.10 Requires-Python >=3.6,<3.8; 1.10.11 Requires-Python >=3.6,<3.8; 1.10.12 Requires-Python >=3.6,<3.8; 1.10.13 Requires-Python >=3.6,<3.8; 1.10.14 Requires-Python >=3.6,<3.8; 1.10.15 Requires-Python >=3.6,<3.8; 1.10.16 Requires-Python >=3.6,<3.8; 1.10.17 Requires-Python >=3.6,<3.8; 1.10.18 Requires-Python >=3.6,<3.8; 1.10.19 Requires-Python >=3.6,<3.8; 1.10.20 Requires-Python >=3.6,<3.8; 1.10.21 Requires-Python >=3.6,<3.8; 1.10.22 Requires-Python >=3.6,<3.8; 1.10.23 Requires-Python >=3.6,<3.8; 1.10.24 Requires-Python >=3.6,<3.8; 1.10.25 Requires-Python >=3.6,<3.8; 1.10.26 Requires-Python >=3.6,<3.8; 1.10.3 Requires-Python >=3.6,<3.8; 1.10.4 Requires-Python >=3.6,<3.8; 1.10.5 Requires-Python >=3.6,<3.8; 1.10.6 Requires-Python >=3.6,<3.8; 1.10.7 Requires-Python >=3.6,<3.8; 1.10.8 Requires-Python >=3.6,<3.8; 1.10.9 Requires-Python >=3.6,<3.8; 2.0.0 Requires-Python >=3.6,<3.9; 2.0.0a1 Requires-Python >=3.6,<3.9; 2.0.0a2 Requires-Python >=3.6,<3.9; 2.0.0a3 Requires-Python >=3.6,<3.9; 2.0.0a4 Requires-Python >=3.6,<3.9; 2.0.0a5 Requires-Python >=3.6,<3.9; 2.0.0a6 Requires-Python >=3.6,<3.9; 2.0.0rc1 Requires-Python >=3.6,<3.9; 2.0.0rc2 Requires-Python >=3.6,<3.9; 2.0.0rc3 Requires-Python >=3.6,<3.9; 2.0.0rc4 Requires-Python >=3.6,<3.9; 2.0.1 Requires-Python >=3.6,<3.9; 2.0.2 Requires-Python >=3.6,<3.9; 2.0.3 Requires-Python >=3.6,<3.9; 2.0.4 Requires-Python >=3.6,<3.9; 2.0.5 Requires-Python >=3.6,<3.9; 2.0.6 Requires-Python >=3.6,<3.9; 2.0.7 Requires-Python >=3.6,<3.9; 2.0.8 Requires-Python >=3.6,<3.9; 2.1.0 Requires-Python >=3.6,<3.9; 2.1.1 Requires-Python >=3.6,<3.9; 2.1.2 Requires-Python >=3.6,<3.9; 2.1.3 Requires-Python >=3.6,<3.9; 2.2.0 Requires-Python >=3.6,<3.9; 2.2.0a1 Requires-Python >=3.6,<3.9; 2.2.1 Requires-Python >=3.6,<3.9; 2.2.10 Requires-Python >=3.6,<3.9; 2.2.2 Requires-Python >=3.6,<3.9; 2.2.3 Requires-Python >=3.6,<3.9; 2.2.4 Requires-Python >=3.6,<3.9; 2.2.5 Requires-Python >=3.6,<3.9; 2.2.6 Requires-Python >=3.6,<3.9; 2.2.7 Requires-Python >=3.6,<3.9; 2.2.8 Requires-Python >=3.6,<3.9; 2.2.9 Requires-Python >=3.6,<3.9; 2.3.0 Requires-Python >=3.6,<3.9; 2.3.1 Requires-Python >=3.6,<3.9; 2.3.2 Requires-Python >=3.6,<3.9; 2.3.3 Requires-Python >=3.6,<3.9; 2.3.4 Requires-Python >=3.6,<3.9; 2.3.5 Requires-Python >=3.6,<3.9; 2.4.0 Requires-Python >=3.6,<3.9; 2.4.1 Requires-Python >=3.6,<3.9; 2.4.2 Requires-Python >=3.6,<3.9; 2.4.3 Requires-Python >=3.6,<3.9; 2.5.0 Requires-Python >=3.6,<3.9; 2.5.1 Requires-Python >=3.6,<3.9; 2.5.2 Requires-Python >=3.6,<3.9; 2.6.0 Requires-Python >=3.6,<3.9; 2.6.1 Requires-Python >=3.6,<3.9; 2.6.2 Requires-Python >=3.6,<3.9; 2.6.3 Requires-Python >=3.6,<3.9; 2.7.0 Requires-Python >=3.6,<3.9; 2.7.1 Requires-Python >=3.6,<3.9; 2.7.2 Requires-Python >=3.6,<3.9; 2.8.0 Requires-Python >=3.6,<3.9; 2.8.1 Requires-Python >=3.6,<3.9; 2.8.10 Requires-Python >=3.6,<3.9; 2.8.11 Requires-Python >=3.6,<3.9; 2.8.12 Requires-Python >=3.6,<3.9; 2.8.13 Requires-Python >=3.6,<3.9; 2.8.14 Requires-Python >=3.6,<3.9; 2.8.15 Requires-Python >=3.6,<3.9; 2.8.16 Requires-Python >=3.6,<3.9; 2.8.17 Requires-Python >=3.6,<3.9; 2.8.18 Requires-Python >=3.6,<3.9; 2.8.19 Requires-Python >=3.6,<3.9; 2.8.2 Requires-Python >=3.6,<3.9; 2.8.20 Requires-Python >=3.6,<3.9; 2.8.21 Requires-Python >=3.6,<3.9; 2.8.22 Requires-Python >=3.6,<3.9; 2.8.23 Requires-Python >=3.6,<3.9; 2.8.24 Requires-Python >=3.6,<3.9; 2.8.25 Requires-Python >=3.6,<3.9; 2.8.26 Requires-Python >=3.6,<3.9; 2.8.27 Requires-Python >=3.7,<3.9; 2.8.28 Requires-Python >=3.7,<3.9; 2.8.29 Requires-Python >=3.7,<3.9; 2.8.3 Requires-Python >=3.6,<3.9; 2.8.30 Requires-Python >=3.7,<3.9; 2.8.31 Requires-Python >=3.7,<3.9; 2.8.32 Requires-Python >=3.7,<3.9; 2.8.33 Requires-Python >=3.7,<3.9; 2.8.34 Requires-Python >=3.7,<3.9; 2.8.4 Requires-Python >=3.6,<3.9; 2.8.5 Requires-Python >=3.6,<3.9; 2.8.6 Requires-Python >=3.6,<3.9; 2.8.7 Requires-Python >=3.6,<3.9; 2.8.8 Requires-Python >=3.6,<3.9; 2.8.9 Requires-Python >=3.6,<3.9; 3.0.0 Requires-Python >=3.7,<3.9; 3.0.0rc1 Requires-Python >=3.7,<3.9; 3.0.0rc2 Requires-Python >=3.7,<3.9; 3.0.0rc3 Requires-Python >=3.7,<3.9; 3.0.1 Requires-Python >=3.7,<3.9; 3.0.11 Requires-Python >=3.7,<3.9; 3.0.12 Requires-Python >=3.7,<3.9; 3.0.13 Requires-Python >=3.7,<3.9; 3.0.2 Requires-Python >=3.7,<3.9; 3.0.3 Requires-Python >=3.7,<3.9; 3.0.4 Requires-Python >=3.7,<3.9; 3.0.5 Requires-Python >=3.7,<3.9; 3.0.6 Requires-Python >=3.7,<3.9; 3.0.7 Requires-Python >=3.7,<3.9; 3.0.8 Requires-Python >=3.7,<3.9; 3.0.9 Requires-Python >=3.7,<3.9; 3.1.0 Requires-Python >=3.7,<3.10; 3.1.1 Requires-Python >=3.7,<3.10; 3.1.2 Requires-Python >=3.7,<3.10; 3.1.3 Requires-Python >=3.7,<3.10; 3.1.4 Requires-Python >=3.7,<3.10; 3.1.5 Requires-Python >=3.7,<3.10; 3.1.6 Requires-Python >=3.7,<3.10; 3.1.7 Requires-Python >=3.7,<3.10; 3.2.0 Requires-Python >=3.7,<3.10; 3.2.1 Requires-Python >=3.7,<3.10; 3.2.10 Requires-Python >=3.7,<3.10; 3.2.11 Requires-Python >=3.7,<3.10; 3.2.12 Requires-Python >=3.7,<3.10; 3.2.13 Requires-Python >=3.7,<3.10; 3.2.2 Requires-Python >=3.7,<3.10; 3.2.4 Requires-Python >=3.7,<3.10; 3.2.5 Requires-Python >=3.7,<3.10; 3.2.6 Requires-Python >=3.7,<3.10; 3.2.7 Requires-Python >=3.7,<3.10; 3.2.8 Requires-Python >=3.7,<3.10; 3.3.0 Requires-Python >=3.7,<3.10; 3.3.0a1 Requires-Python >=3.7,<3.10; 3.3.1 Requires-Python >=3.7,<3.10; 3.3.10 Requires-Python >=3.7,<3.10; 3.3.11 Requires-Python >=3.7,<3.10; 3.3.12 Requires-Python >=3.7,<3.10; 3.3.2 Requires-Python >=3.7,<3.10; 3.3.3 Requires-Python >=3.7,<3.10; 3.3.4 Requires-Python >=3.7,<3.10; 3.3.5 Requires-Python >=3.7,<3.10; 3.3.6 Requires-Python >=3.7,<3.10; 3.3.7 Requires-Python >=3.7,<3.10; 3.3.8 Requires-Python >=3.7,<3.10; 3.3.9 Requires-Python >=3.7,<3.10\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow~=1.13.0 (from rasa) (from versions: 2.8.0rc0, 2.8.0rc1, 2.8.0, 2.8.1, 2.8.2, 2.8.3, 2.8.4, 2.9.0rc0, 2.9.0rc1, 2.9.0rc2, 2.9.0, 2.9.1, 2.9.2, 2.9.3, 2.10.0rc0, 2.10.0rc1, 2.10.0rc2, 2.10.0rc3, 2.10.0, 2.10.1, 2.11.0rc0, 2.11.0rc1, 2.11.0rc2, 2.11.0, 2.11.1, 2.12.0rc0, 2.12.0rc1, 2.12.0, 2.12.1, 2.13.0rc0, 2.13.0rc1, 2.13.0rc2, 2.13.0, 2.13.1, 2.14.0rc0, 2.14.0rc1, 2.14.0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for tensorflow~=1.13.0\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7fV_o41CSA-L"
      },
      "outputs": [],
      "source": [
        "# Import all the necessary dependcies\n",
        "\n",
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import imread\n",
        "import scipy\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.layers as tfl\n",
        "from tensorflow.python.framework import ops"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You will have to make an account on kaggle and will have to use that 'username' and key."
      ],
      "metadata": {
        "id": "J5VzIMhTXZ3U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the dataset from kaggle\n",
        "\n",
        "\n",
        "import opendatasets as od\n",
        "import pandas as pd\n",
        "od.download(\"https://www.kaggle.com/datasets/koryakinp/fingers\")"
      ],
      "metadata": {
        "id": "H8UP354FV2oh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "32ab68e3-6cf4-4aae-9062-0ef803d319f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
            "Your Kaggle username:"
          ]
        },
        {
          "output_type": "error",
          "ename": "Abort",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAbort\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-ad1f4f553429>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mopendatasets\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"https://www.kaggle.com/datasets/koryakinp/fingers\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/opendatasets/__init__.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(dataset_id_or_url, data_dir, force, dry_run, **kwargs)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# Check for a Kaggle dataset URL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_kaggle_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_id_or_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdownload_kaggle_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_id_or_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdry_run\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdry_run\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# Check for Google Drive URL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/opendatasets/utils/kaggle_api.py\u001b[0m in \u001b[0;36mdownload_kaggle_dataset\u001b[0;34m(dataset_url, data_dir, force, dry_run)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mread_kaggle_creds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'KAGGLE_USERNAME'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclick\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Your Kaggle username\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'KAGGLE_KEY'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_kaggle_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/click/termui.py\u001b[0m in \u001b[0;36mprompt\u001b[0;34m(text, default, hide_input, confirmation_prompt, type, value_proc, prompt_suffix, show_default, err, show_choices)\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprompt_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/click/termui.py\u001b[0m in \u001b[0;36mprompt_func\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhide_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m                 \u001b[0mecho\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAbort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalue_proc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAbort\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Path to the dataset directory\n",
        "dataset_dir = '/content/fingers/test'\n",
        "\n",
        "# Initialize lists to store images and labels\n",
        "images = []\n",
        "labels = []\n",
        "\n",
        "# Iterate through each image file\n",
        "for filename in os.listdir(dataset_dir):\n",
        "    # Load the image using OpenCV\n",
        "\n",
        "\n",
        "    # Resize the image to a desired size (e.g., 64x64)\n",
        "\n",
        "\n",
        "    # Append the image to the images list\n",
        "\n",
        "\n",
        "    # Get the label from the filename (the first character)\n",
        "\n",
        "\n",
        "    # Append the label to the labels list\n",
        "\n",
        "\n",
        "# Convert the lists to NumPy arrays\n",
        "\n"
      ],
      "metadata": {
        "id": "ly-YcGDjMVFq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = np.expand_dims(x_train, axis=-1)\n",
        "x_test = np.expand_dims(x_test, axis=-1)"
      ],
      "metadata": {
        "id": "eyO82oK4bzct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "\n",
        "Y_train = to_categorical(y_train, num_classes=6)\n",
        "\n",
        "Y_test = to_categorical(y_test, num_classes=6)"
      ],
      "metadata": {
        "id": "LalU-m8ed9tI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (\"Y_train shape: \" + str(Y_train.shape))\n",
        "print (\"Y_test shape: \" + str(Y_test.shape))"
      ],
      "metadata": {
        "id": "eGg9wTjWZJnO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MAKE YOUR CNN MODEL HERE\n",
        "\n",
        "def convolutional_model(input_shape):\n",
        "\n",
        "    input_img = tf.keras.Input(shape=input_shape)\n",
        "    ## CONV2D: 8 filters 4x4, stride of 1, padding 'SAME'\n",
        "\n",
        "    ##  Apply RELU to previous layer\n",
        "\n",
        "    ## MAXPOOL: window 8x8, stride 8, padding 'SAME'\n",
        "\n",
        "    ## CONV2D: 16 filters 2x2, stride 1, padding 'SAME'\n",
        "\n",
        "    ## RELU\n",
        "\n",
        "    ## MAXPOOL: window 4x4, stride 4, padding 'SAME'\n",
        "\n",
        "    ## FLATTEN\n",
        "\n",
        "    ## Dense layer\n",
        "    ## 6 neurons in output layer. Hint: one of the arguments should be \"activation='softmax'\"\n",
        "\n",
        "    # return your model:\n"
      ],
      "metadata": {
        "id": "JIMLdalLXtPl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# COMPILE YOUR MODEL HERE\n",
        "\n",
        "conv_model = convolutional_model((64, 64,1))\n",
        "conv_model.compile(optimizer=.....,\n",
        "                  loss=.....,\n",
        "                  metrics=.....)\n",
        "conv_model.summary()"
      ],
      "metadata": {
        "id": "8BdaQ2alTT9v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SLICE THE DATASET FOR 1800 IMAGES FOR TRAINING AND 300 FOR TESTING, ALSO MENTION THE BATCH SIZE\n",
        "\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train[.....], Y_train[.....]))\n",
        "train_dataset = train_dataset.batch(.....)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((x_test[.....], Y_test[.....]))\n",
        "test_dataset = test_dataset.batch(.....)\n"
      ],
      "metadata": {
        "id": "eQBPWlDATXQI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TWEAK THE NUMBER OF IMAGES TO GET BETTER RESULTS\n",
        "\n",
        "history = conv_model.fit(train_dataset, epochs=....., validation_data=test_dataset)"
      ],
      "metadata": {
        "id": "w0tKznpya0im"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PLOT YOUR RESULTS HERE\n"
      ],
      "metadata": {
        "id": "1Nm9s2JxiJAK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import cv2\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "numbers = list(range(1, 1001))\n",
        "random_array = random.sample(numbers, 10)\n",
        "\n",
        "fig = plt.figure(figsize=(10, 7))\n",
        "\n",
        "for i, idx in enumerate(random_array):\n",
        "    img_resized = cv2.resize(x_test[idx], (64, 64))\n",
        "    y_pred = np.argmax(conv_model.predict(np.expand_dims(x_test[idx], axis=0),verbose=0))\n",
        "    ax = fig.add_subplot(1, 10, i+1)\n",
        "    ax.imshow(img_resized, cmap='gray')\n",
        "    ax.axis('off')\n",
        "    ax.set_title(\"pred = \" + str(y_pred))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cssoYMXsbi4X"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}